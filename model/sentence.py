from nltk.tokenize import sent_tokenize

"""
IMPLEMENT ALL POSSIBLE SENTENCE TOKENIZERS HERE
"""


def text_tokenize(text):
    return sent_tokenize(text)
